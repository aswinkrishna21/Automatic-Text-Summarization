{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":4,"outputs":[{"output_type":"stream","text":"/kaggle/input/text-summarization/Amazon Product Reviews.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":5,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/text-summarization/Amazon Product Reviews.csv\")\ndf.head()","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>ProductId</th>\n      <th>UserId</th>\n      <th>ProfileName</th>\n      <th>HelpfulnessNumerator</th>\n      <th>HelpfulnessDenominator</th>\n      <th>Score</th>\n      <th>Time</th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>B001E4KFG0</td>\n      <td>A3SGXH7AUHU8GW</td>\n      <td>delmartian</td>\n      <td>1</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1303862400</td>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>B00813GRG4</td>\n      <td>A1D87F6ZCVE5NK</td>\n      <td>dll pa</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1346976000</td>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>B000LQOCH0</td>\n      <td>ABXLMWJIXXAIN</td>\n      <td>Natalia Corres \"Natalia Corres\"</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1219017600</td>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>B000UA0QIQ</td>\n      <td>A395BORC6FGVXV</td>\n      <td>Karl</td>\n      <td>3</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1307923200</td>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>B006K2ZZ7K</td>\n      <td>A1UQRSCLF8GW1T</td>\n      <td>Michael D. Bigham \"M. Wassir\"</td>\n      <td>0</td>\n      <td>0</td>\n      <td>5</td>\n      <td>1350777600</td>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.dropna()","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import torch\nuse_gpu = torch.cuda.is_available()\nprint(use_gpu)","execution_count":8,"outputs":[{"output_type":"stream","text":"True\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df = df.drop(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator', 'HelpfulnessDenominator',\n                       'Score', 'Time'], 1)\ndf = df.reset_index(drop = True)","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head(10)","execution_count":10,"outputs":[{"output_type":"execute_result","execution_count":10,"data":{"text/plain":"                                         Summary  \\\n0                          Good Quality Dog Food   \n1                              Not as Advertised   \n2                          \"Delight\" says it all   \n3                                 Cough Medicine   \n4                                    Great taffy   \n5                                     Nice Taffy   \n6  Great!  Just as good as the expensive brands!   \n7                         Wonderful, tasty taffy   \n8                                     Yay Barley   \n9                               Healthy Dog Food   \n\n                                                Text  \n0  I have bought several of the Vitality canned d...  \n1  Product arrived labeled as Jumbo Salted Peanut...  \n2  This is a confection that has been around a fe...  \n3  If you are looking for the secret ingredient i...  \n4  Great taffy at a great price.  There was a wid...  \n5  I got a wild hair for taffy and ordered this f...  \n6  This saltwater taffy had great flavors and was...  \n7  This taffy is so good.  It is very soft and ch...  \n8  Right now I'm mostly just sprouting this so my...  \n9  This is a very healthy dog food. Good for thei...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Summary</th>\n      <th>Text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Good Quality Dog Food</td>\n      <td>I have bought several of the Vitality canned d...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Not as Advertised</td>\n      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>\"Delight\" says it all</td>\n      <td>This is a confection that has been around a fe...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Cough Medicine</td>\n      <td>If you are looking for the secret ingredient i...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Great taffy</td>\n      <td>Great taffy at a great price.  There was a wid...</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>Nice Taffy</td>\n      <td>I got a wild hair for taffy and ordered this f...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>Great!  Just as good as the expensive brands!</td>\n      <td>This saltwater taffy had great flavors and was...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>Wonderful, tasty taffy</td>\n      <td>This taffy is so good.  It is very soft and ch...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>Yay Barley</td>\n      <td>Right now I'm mostly just sprouting this so my...</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>Healthy Dog Food</td>\n      <td>This is a very healthy dog food. Good for thei...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(5):\n    print(\"Review \", i+1, ':')\n    print('Summary: ', df['Summary'][i])\n    print('Text: ', df['Text'][i])\n    print('\\n')","execution_count":11,"outputs":[{"output_type":"stream","text":"Review  1 :\nSummary:  Good Quality Dog Food\nText:  I have bought several of the Vitality canned dog food products and have found them all to be of good quality. The product looks more like a stew than a processed meat and it smells better. My Labrador is finicky and she appreciates this product better than  most.\n\n\nReview  2 :\nSummary:  Not as Advertised\nText:  Product arrived labeled as Jumbo Salted Peanuts...the peanuts were actually small sized unsalted. Not sure if this was an error or if the vendor intended to represent the product as \"Jumbo\".\n\n\nReview  3 :\nSummary:  \"Delight\" says it all\nText:  This is a confection that has been around a few centuries.  It is a light, pillowy citrus gelatin with nuts - in this case Filberts. And it is cut into tiny squares and then liberally coated with powdered sugar.  And it is a tiny mouthful of heaven.  Not too chewy, and very flavorful.  I highly recommend this yummy treat.  If you are familiar with the story of C.S. Lewis' \"The Lion, The Witch, and The Wardrobe\" - this is the treat that seduces Edmund into selling out his Brother and Sisters to the Witch.\n\n\nReview  4 :\nSummary:  Cough Medicine\nText:  If you are looking for the secret ingredient in Robitussin I believe I have found it.  I got this in addition to the Root Beer Extract I ordered (which was good) and made some cherry soda.  The flavor is very medicinal.\n\n\nReview  5 :\nSummary:  Great taffy\nText:  Great taffy at a great price.  There was a wide assortment of yummy taffy.  Delivery was very quick.  If your a taffy lover, this is a deal.\n\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"contractions = {\n    \"ain't\": \"am not\", \"aren't\": \"are not\", \"can't\": \"cannot\", \"can't've\": \"cannot have\", \"'cause\": \"because\", \"could've\": \"could have\",\n    \"couldn't\": \"could not\", \"couldn't've\": \"could not have\", \"didn't\": \"did not\", \"doesn't\": \"does not\", \"don't\": \"do not\",\n    \"hadn't\": \"had not\", \"hadn't've\": \"had not have\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\n    \"he'd've\": \"he would have\", \"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'll\": \"how will\", \"how's\": \"how is\",\n    \"i'd\": \"i would\", \"i'll\": \"i will\", \"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\",\n    \"it'll\": \"it will\", \"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\n    \"mightn't\": \"might not\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"needn't\": \"need not\", \"oughtn't\": \"ought not\",\n    \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"she'd\": \"she would\", \"she'll\": \"she will\",\"she's\": \"she is\", \"should've\": \"should have\", \n    \"shouldn't\": \"should not\", \"that'd\": \"that would\", \"that's\": \"that is\", \"there'd\": \"there had\", \"there's\": \"there is\",\n    \"they'd\": \"they would\", \"they'll\": \"they will\", \"they're\": \"they are\", \"they've\": \"they have\", \"wasn't\": \"was not\",\n    \"we'd\": \"we would\", \"we'll\": \"we will\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\",\n    \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"where'd\": \"where did\", \"where's\": \"where is\",\n    \"who'll\": \"who will\", \"who's\": \"who is\", \"won't\": \"will not\", \"wouldn't\": \"would not\", \"you'd\": \"you would\",\n    \"you'll\": \"you will\", \"you're\": \"you are\"\n}","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from nltk.corpus import stopwords","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def clean_text(text, remove_stopwords = True):\n    text = text.lower()\n    \n    if True:\n        text = text.split()\n        new_text = []\n        for word in text:\n            if word in contractions:\n                new_text.append(contractions[word])\n            else:\n                new_text.append(word)\n        text = ' '.join(new_text)\n    \n    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n    text = re.sub(r'\\<a href', ' ', text)\n    text = re.sub(r'&amp;', '', text) \n    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n    text = re.sub(r'<br />', ' ', text)\n    text = re.sub(r'\\'', ' ', text)\n    \n    if remove_stopwords:\n        text = text.split()\n        stops = set(stopwords.words('english'))\n        text = [w for w in text if w not in stops]\n        text = \" \".join(text)\n    \n    return text","execution_count":14,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will remove the stopwords from the reviews but keep them in the summaries so that they sound like natural phrases"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Clean the summaries and texts\nclean_summaries = []\nfor summary in df['Summary']:\n    clean_summaries.append(clean_text(summary, remove_stopwords = False))\nprint(\"Summaries are complete.\")\n\nclean_texts = []\nfor text in df['Text']:\n    clean_texts.append(clean_text(text))\nprint(\"Texts are complete.\")","execution_count":15,"outputs":[{"output_type":"stream","text":"Summaries are complete.\nTexts are complete.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Inspect the cleaned summaries and texts to ensure they have been cleaned well\nfor i in range(5):\n    print(\"Clean Review #\",i+1)\n    print(clean_summaries[i])\n    print(clean_texts[i])\n    print()","execution_count":16,"outputs":[{"output_type":"stream","text":"Clean Review # 1\ngood quality dog food\nbought several vitality canned dog food products found good quality product looks like stew processed meat smells better labrador finicky appreciates product better\n\nClean Review # 2\nnot as advertised\nproduct arrived labeled jumbo salted peanuts peanuts actually small sized unsalted sure error vendor intended represent product jumbo\n\nClean Review # 3\n delight  says it all\nconfection around centuries light pillowy citrus gelatin nuts case filberts cut tiny squares liberally coated powdered sugar tiny mouthful heaven chewy flavorful highly recommend yummy treat familiar story c lewis lion witch wardrobe treat seduces edmund selling brother sisters witch\n\nClean Review # 4\ncough medicine\nlooking secret ingredient robitussin believe found got addition root beer extract ordered good made cherry soda flavor medicinal\n\nClean Review # 5\ngreat taffy\ngreat taffy great price wide assortment yummy taffy delivery quick taffy lover deal\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_dict = {}\ndef count_words(text):\n    for sentence in text:\n        for word in sentence.split():\n            if word not in count_dict:\n                count_dict[word] = 1\n            else:\n                count_dict[word] += 1","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"count_words(clean_summaries)\ncount_words(clean_texts)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(count_dict)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"132884"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install --upgrade tensorflow==1.15","execution_count":20,"outputs":[{"output_type":"stream","text":"Collecting tensorflow==1.15\n  Downloading tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3 MB)\n\u001b[K     |████████████████████████████████| 412.3 MB 22 kB/s s eta 0:00:01   |█                               | 12.8 MB 6.8 MB/s eta 0:00:59     |█████████████████████████████   | 374.7 MB 42.2 MB/s eta 0:00:01     |█████████████████████████████▎  | 376.5 MB 42.2 MB/s eta 0:00:01     |██████████████████████████████  | 385.2 MB 42.2 MB/s eta 0:00:01     |██████████████████████████████▌ | 392.3 MB 18.3 MB/s eta 0:00:02\n\u001b[?25hCollecting tensorflow-estimator==1.15.1\n  Downloading tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503 kB)\n\u001b[K     |████████████████████████████████| 503 kB 21.7 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.31.0)\nRequirement already satisfied, skipping upgrade: wheel>=0.26 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.34.2)\nCollecting keras-applications>=1.0.8\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n\u001b[K     |████████████████████████████████| 50 kB 5.1 MB/s  eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.12.4)\nCollecting gast==0.2.2\n  Downloading gast-0.2.2.tar.gz (10 kB)\nRequirement already satisfied, skipping upgrade: six>=1.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.14.0)\nRequirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.2.0)\nRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.2)\nCollecting astor>=0.6.0\n  Downloading astor-0.8.1-py2.py3-none-any.whl (27 kB)\nRequirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (0.9.0)\nRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.18.5)\nRequirement already satisfied, skipping upgrade: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (3.3.0)\nCollecting tensorboard<1.16.0,>=1.15.0\n  Downloading tensorboard-1.15.0-py3-none-any.whl (3.8 MB)\n\u001b[K     |████████████████████████████████| 3.8 MB 42.5 MB/s eta 0:00:01\n\u001b[?25hRequirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.11.2)\nRequirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==1.15) (1.1.0)\nRequirement already satisfied, skipping upgrade: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\nRequirement already satisfied, skipping upgrade: setuptools in /opt/conda/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow==1.15) (46.1.3.post20200325)\nRequirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\nRequirement already satisfied, skipping upgrade: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.2.1)\nBuilding wheels for collected packages: gast\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7539 sha256=94295d99578262a2809f7f1c4bfdcbe8b47398dbeb357bf188c444459f689094\n  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\nSuccessfully built gast\nInstalling collected packages: tensorflow-estimator, keras-applications, gast, astor, tensorboard, tensorflow\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.3.0\n    Uninstalling tensorflow-estimator-2.3.0:\n      Successfully uninstalled tensorflow-estimator-2.3.0\n  Attempting uninstall: gast\n    Found existing installation: gast 0.3.3\n    Uninstalling gast-0.3.3:\n      Successfully uninstalled gast-0.3.3\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.3.0\n    Uninstalling tensorboard-2.3.0:\n      Successfully uninstalled tensorboard-2.3.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.3.0\n    Uninstalling tensorflow-2.3.0:\n      Successfully uninstalled tensorflow-2.3.0\n\u001b[31mERROR: After October 2020 you may experience errors when installing or updating packages. This is because pip will change the way that it resolves dependency conflicts.\n\nWe recommend you use --use-feature=2020-resolver to test your packages with the new resolver before it becomes the default.\n\ntensorflow-probability 0.11.0 requires gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\nSuccessfully installed astor-0.8.1 gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import tensorflow as tf\ntf.__version__","execution_count":21,"outputs":[{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"'1.15.0'"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"I had to downgrade the version of tensorflow because elmo is not compatible with tf2.x"},{"metadata":{"trusted":true},"cell_type":"code","source":"print(clean_texts[50], clean_summaries[50], sep = '\\n')","execution_count":24,"outputs":[{"output_type":"stream","text":"oatmeal good mushy soft like quaker oats way go\ndo not like it\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Torch Req"},{"metadata":{"trusted":true},"cell_type":"code","source":"from __future__ import unicode_literals, print_function, division\nfrom io import open\nimport random\nimport string\nimport unidecode\n\nimport torch\nimport torch.nn as nn\nfrom torch import optim\nfrom torch.autograd import Variable\nimport torch.nn.functional as F","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"glove_path = '../input/glove-200d/glove.6B.200d.txt'","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#creating a dictionary of sorts for the entire corpus\nclass Language:\n    def __init__(self, name):\n        self.name = name\n        self.word2idx = {}\n        self.wordcnt = {}\n        self.n_words = 2 #counting sos and eos initially\n        self.idx2word = {0 : 'SOS', 1 : 'EOS'} #Start of sentence and end of sentence respectively.\n    \n    def addSentence(self, sentence):\n        for word in sentence.split(' '):\n            self.addWord(word)\n    \n    def addWord(self, word):\n        if word not in self.word2idx:\n            self.word2idx[word] = self.n_words\n            self.idx2word[self.n_words] = word\n            self.n_words += 1\n            self.wordcnt[word] = 1\n        else:\n            self.wordcnt[word] += 1","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def readText(text, summary):\n    print(\"Reading text...\")\n    pairs = [[text[i], summary[i]] for i in range(len(text))]\n    \n    input_text = Lang(text)\n    output_text = Lang(summary)\n    return input_text, output_text, pairs","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepareData(text, summary):\n    input_text, output_text, pairs = readText(text, summary)\n    \n    print(\"Read %s sentence pairs\", len(pairs))\n    print(\"Counting words...\")\n    \n    for pair in pairs:\n        input_text.addSentence(pairs[0])\n        output_text.addSentence(pairs[1])\n    print(\"Finished counting words:\")\n    print(input_text.name, input_text.n_words)\n    print(output_text.name, output_text.n_words)\n    return input_text, output_text, pairs","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}